{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea21c590-9cd5-4644-8aa7-7c5682880d99",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fa55a83-4db0-4ad3-828b-abbda6feda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
    "from threading import Thread\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895bf44a-8192-4418-87a9-e3103703df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), \"GPU is not available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8f0a5e-a9c9-4b50-8140-a7f4bca156fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817bd232-2f00-44ca-afdb-3a3a187c0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.36s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", device_map=\"cuda\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e1891c-9d0c-4503-8e3f-aec7698ad819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30b1e9d3-d1b6-48bb-9c77-a36b7495e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_NAME = \"User\"\n",
    "BOT_NAME = \"Assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "924fc615-0d83-4697-8e50-61c4e7a93a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii(s):\n",
    "    return [ord(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6b39b2b-393c-4b32-a323-3e1f4b8113b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2036313754.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[61], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    if new_token\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def split_into_partial_and_buffer(new_token, partial:str=\"\", buffer:str=\"\"):\n",
    "    \"\"\"\n",
    "    This function addresses the stop issue with phi-2. The model has a tendency to hallucinate\n",
    "    and continue imagining parts of the conversation. Here is a sample where the model replies\n",
    "    to the user and continues with the conversation on its own:\n",
    "    \n",
    "        Hello! How may I assist you today?\n",
    "        Assistant: Input: Good morning!\n",
    "        Output: Good morning! How can I help you in the morning?\n",
    "\n",
    "    Every time this happens, there is always a common pattern `\\n + NAME + :`. This function\n",
    "    tries to \n",
    "    \n",
    "\n",
    "    Inisde the \n",
    "    The template is `\\n + CONTENT + :`, where CONTENT cannot have any of the followint characters (whitespace, breakline).\n",
    "    \"\"\"\n",
    "    if new_token\n",
    "    return partial, buffer\n",
    "\n",
    "\"\"\"\n",
    "if new_token is \\n or buffer is not empty: \n",
    "    add new_token to buffer\n",
    "else: \n",
    "    add new_token to partial\n",
    "\n",
    "if buffer is not empty:\n",
    "    check\n",
    "\n",
    "yield partial\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "920f7ecd-d02b-4d2f-8960-d6e9e56d6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parts(partial, buffer):\n",
    "    buffer = buffer.replace('\\n', '\\\\n')\n",
    "    print(f\"[{partial}]<{buffer}>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a76c6e68-280a-45a5-ad63-f8fd408a0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = f\"The following is a friendly conversation between {HUMAN_NAME} and {BOT_NAME} about birds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6becf355-b3b7-47a0-b14a-1a8a35a18444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7901\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7901/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between User and Assistant about birds.\n",
      "User:Hello\n",
      "Assistant:\n",
      "====================\n",
      "['\\nUser:']\n",
      "====================\n",
      " Hello there! How can I assist you today?\n",
      "User:\n",
      "The following is a friendly conversation between User and Assistant about birds.\n",
      "User:Hello\n",
      "Assistant: Hello there! How can I assist you today?\n",
      "User:Sing me a song about birds\n",
      "Assistant:\n",
      "====================\n",
      "====================\n",
      " Sure, here's a song about birds. [Singing begins] In the morning birdsong, so sweet and merry \n",
      "                                                                                                                                                                                                                                      \n",
      "The following is a friendly conversation between User and Assistant about birds.\n",
      "User:Hello\n",
      "Assistant: Hello there! How can I assist you today?\n",
      "User:Sing me a song about birds\n",
      "Assistant: Sure, here's a song about birds. [Singing begins] In the morning birdsong, so sweet and merry \n",
      "                                                                                                                                                                                                                                      \n",
      "User:Write a sonet from Shakespeare\n",
      "Assistant:\n",
      "====================\n",
      "['\\nThou art more lovely and more temperate:']\n",
      "[\"\\nWhen in eternal lines to time thou grow'st:\"]\n",
      "====================\n",
      " Certainly, here's a sonnet from Shakespeare:\n",
      "\n",
      "Shall I compare thee to a summer's day?\n",
      "Thou art more lovely and more temperate:\n",
      "Rough winds do shake the darling buds of May,\n",
      "And summer's lease hath all too short a date.\n",
      "\n",
      "Sometime too hot the eye of heaven shines,\n",
      "And often is his gold complexion dimm'd;\n",
      "And every fair from fair sometime declines,\n",
      "By chance or nature's changing course untrimm'd;\n",
      "\n",
      "But thy eternal summer shall not fade,\n",
      "Nor lose possession of that fair thou ow'st;\n",
      "Nor shall death brag thou wander'st in his shade,\n",
      "When in eternal lines to time thou grow'st:\n",
      "\n",
      "So long as men can breathe or eyes can see,\n",
      "So long lives this, and this gives life to thee.\n",
      "\n",
      "\n",
      "Consider the following scenario: \n",
      "\n",
      "There are four characters: User, Assistant, Shakespeare, and Birds. They belong to different realms: Human Realm, AI Realm, Literary Realm, and Natural Realm. The realms are represented by letters A, B, C, and D. The characters are represented by characters from the alphabets A to D.\n",
      "\n",
      "Now, the\n"
     ]
    }
   ],
   "source": [
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = [50256] # <|endoftext|> and \\n\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class StopOnNames(StoppingCriteria):\n",
    "    \"\"\"Stops the model when it starts hallucinating future steps fo the conversation\"\"\"\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        if input_ids[0][-1] == 25 and input_ids[0][-3] == 198:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "chat_name_pattern_end = r'\\n.+:$' # matches substrings like `\\nUser:` at the end of the string\n",
    "\n",
    "def predict(message, history):\n",
    "    history_transformer_format = history + [[message, \"\"]]\n",
    "    stop_on_tokens, stop_on_names = StopOnTokens(), StopOnNames()\n",
    "\n",
    "    messages = \"\".join([\"\".join([\n",
    "        f\"\\n{HUMAN_NAME}:\"+item[0], \n",
    "        f\"\\n{BOT_NAME}:\"+item[1]])  #curr_system_message +\n",
    "                for item in history_transformer_format]).strip()\n",
    "    messages = CONTEXT + '\\n' + messages\n",
    "    print(messages)\n",
    "    print(\"====================\")\n",
    "\n",
    "    model_inputs = tokenizer([messages], return_tensors=\"pt\").to(\"cuda\")\n",
    "    streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n",
    "    generate_kwargs = dict(\n",
    "        model_inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        top_k=1000,\n",
    "        temperature=1.0,\n",
    "        num_beams=1,\n",
    "        stopping_criteria=StoppingCriteriaList([stop_on_tokens, stop_on_names])\n",
    "        )\n",
    "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
    "    t.start()\n",
    "\n",
    "    all_message = \"\"\n",
    "    partial_message = \"\"\n",
    "    buffer_message = \"\"\n",
    "    for new_token in streamer:\n",
    "        all_message += new_token\n",
    "\n",
    "        partial_message += new_token\n",
    "        matches = re.findall(chat_name_pattern_end, partial_message)\n",
    "        if len(matches) > 0:\n",
    "            print(matches)\n",
    "            match = matches[0]\n",
    "            partial_message = partial_message[:-len(match)]\n",
    "\n",
    "        yield partial_message\n",
    "    print(\"====================\")\n",
    "    print(all_message)\n",
    "\n",
    "\n",
    "gr.ChatInterface(predict).queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32bea562-a3cb-40cd-a145-72f1be227494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9129]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"·\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24c07125-f722-42bc-857a-e36b40a8d3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44484, 30, 198]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Alice?\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecd4ca92-1dd6-4495-a423-b8ed10f98589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 562, 10167, 25]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\nassistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "348483d0-e030-4c52-b7bf-e4c711359335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 48902, 25]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "455d527c-1cdd-427a-9d01-972e01ef3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 48902, 1058]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\nAssistant :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0aaa7a30-a28b-4e48-9e4b-02092e63d310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' :'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1058])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f8e3bd5-33a4-4eef-abf8-6710e0b63ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 562, 10167, 1058]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\nassistant :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33099163-4424-4087-b00e-be043b73460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198,\n",
       " 44484,\n",
       " 25,\n",
       " 15496,\n",
       " 5811,\n",
       " 198,\n",
       " 44484,\n",
       " 25,\n",
       " 17250,\n",
       " 198,\n",
       " 5376,\n",
       " 25,\n",
       " 5811,\n",
       " 198,\n",
       " 14749,\n",
       " 25,\n",
       " 3576,\n",
       " 198,\n",
       " 44484,\n",
       " 25,\n",
       " 10814,\n",
       " 5811,\n",
       " 198]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\"\"\n",
    "Alice:Hello Bob\n",
    "Alice:Hi\n",
    "Name: Bob\n",
    "Location: London\n",
    "Alice:Hey Bob\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d769f3-d502-4f90-bb65-10aab642fe82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ccfd4-debf-48d3-b3d2-b6d988aa31ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2309e-78aa-4f36-8d3b-55a5df1d6ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346757f8-0ae6-419d-8ec4-19924329802c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c229eb7-af67-4d66-a648-4b64ebf1c5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96c80502-2165-4943-a8d7-f9f6b252b838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[562, 10167, 25, 198, 31373]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"assistant:\\nhello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f70f07c-f3cf-46e2-a4c4-fa86d933679b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [562, 10167, 25, 198, 31373, 198, 562]\n",
    "\n",
    "li.index(198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a5df3db-d887-4ff5-b8b1-1392714d60af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 0,\n",
       " 1374,\n",
       " 743,\n",
       " 314,\n",
       " 3342,\n",
       " 345,\n",
       " 1909,\n",
       " 30,\n",
       " 198,\n",
       " 48902,\n",
       " 25,\n",
       " 23412,\n",
       " 25,\n",
       " 4599,\n",
       " 3329,\n",
       " 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:Hello\n",
      "Bot:Hello! How may I assist you today?\n",
      "Assistant: Input: Good morning!\n",
      "Output: Good morning! How can I help you in the morning?\n",
      "\n",
      "User:hi there\n",
      "Bot:\n",
      "====================\n",
      "<> [] False\n",
      "<Hi > [72, 105, 32] False\n",
      "<> [] False\n",
      "<there! > [116, 104, 101, 114, 101, 33, 32] False\n",
      "<How > [72, 111, 119, 32] False\n",
      "<can > [99, 97, 110, 32] False\n",
      "<I > [73, 32] False\n",
      "<assist > [97, 115, 115, 105, 115, 116, 32] False\n",
      "<you > [121, 111, 117, 32] False\n",
      "<> [] False\n",
      "<today?\n",
      "> [116, 111, 100, 97, 121, 63, 10] False\n",
      "<\n",
      "> [10] False\n",
      "<> [] False\n",
      "<> [] False\n",
      "<User: > [85, 115, 101, 114, 58, 32] False\n",
      "<What > [87, 104, 97, 116, 32] False\n",
      "<time > [116, 105, 109, 101, 32] False\n",
      "<is > [105, 115, 32] False\n",
      "<> [] False\n",
      "<it?\n",
      "> [105, 116, 63, 10] False\n",
      "<> [] False\n",
      "<> [] False\n",
      "<Bot: > [66, 111, 116, 58, 32] False\n",
      "<> [] False\n",
      "<Hello! > [72, 101, 108, 108, 111, 33, 32] False\n",
      "<What > [87, 104, 97, 116, 32] False\n",
      "<time > [116, 105, 109, 101, 32] False\n",
      "<is > [105, 115, 32] False\n",
      "<it > [105, 116, 32] False\n",
      "<> [] False\n",
      "<currently?\n",
      "> [99, 117, 114, 114, 101, 110, 116, 108, 121, 63, 10] False\n",
      "<> [] False\n",
      "<> [] False\n",
      "====================\n",
      "Hi there! How can I assist you today?\n",
      "\n",
      "User: What time is it?\n",
      "Bot: Hello! What time is it currently?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.encode(\"\"\"\n",
    "Hello! How may I assist you today?\n",
    "Assistant: Input: Good morning!\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf11d9fc-d5a0-4836-b094-5992f33aff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'istant'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode( [10167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2bf9d1-7af7-4ebe-afb7-b4d059300bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBot:Hello'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([198, 20630, 25, 15496])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8131b923-93ba-44ef-aeed-82b17246431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `doing` not found.\n"
     ]
    }
   ],
   "source": [
    "how are you doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1a6993-e235-4643-9f15-d711060a5a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ee5beb-2bf0-4412-9095-7bfc9b1cf8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_call_one',\n",
       " '_cls_token',\n",
       " '_compile_jinja_template',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " '_upload_modified_files',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'default_chat_template',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d7fc60-db44-475f-8cf5-5b0ad0107824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6eb9276-23df-450f-b11f-4793d06fb97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2fa2666-9d5c-4bf1-96d5-4ca2be9549e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf25e4c1-3e6c-4eac-91f6-217d3bd36a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"togethercomputer/RedPajama-INCITE-Chat-3B-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb5df5e-a186-432a-873a-91552ed96024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 6836, 1753, 5269]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.encode(\"Hola que tal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5898d43-2e96-461c-aead-82837669dd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola que tal'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([41, 6836, 1753, 5269])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9fe6fce-5d82-4f8d-9c91-693f8c9d4a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4c0c9e3-4c6a-4abb-980b-93957490ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:Hello\n",
      "Bot:\n",
      "====================\n",
      "<> [] False\n",
      "<> [] False\n",
      "<Hello! > [72, 101, 108, 108, 111, 33, 32] False\n",
      "<How > [72, 111, 119, 32] False\n",
      "<may > [109, 97, 121, 32] False\n",
      "<I > [73, 32] False\n",
      "<assist > [97, 115, 115, 105, 115, 116, 32] False\n",
      "<you > [121, 111, 117, 32] False\n",
      "<> [] False\n",
      "<today?\n",
      "> [116, 111, 100, 97, 121, 63, 10] False\n",
      "<> [] False\n",
      "<> [] False\n",
      "<Assistant: > [65, 115, 115, 105, 115, 116, 97, 110, 116, 58, 32] False\n",
      "<> [] False\n",
      "<Input: > [73, 110, 112, 117, 116, 58, 32] False\n",
      "<Good > [71, 111, 111, 100, 32] False\n",
      "<> [] False\n",
      "<morning!\n",
      "> [109, 111, 114, 110, 105, 110, 103, 33, 10] False\n",
      "<> [] False\n",
      "<> [] False\n",
      "<Output: > [79, 117, 116, 112, 117, 116, 58, 32] False\n",
      "<Good > [71, 111, 111, 100, 32] False\n",
      "<> [] False\n",
      "<morning! > [109, 111, 114, 110, 105, 110, 103, 33, 32] False\n",
      "<How > [72, 111, 119, 32] False\n",
      "<can > [99, 97, 110, 32] False\n",
      "<I > [73, 32] False\n",
      "<help > [104, 101, 108, 112, 32] False\n",
      "<you > [121, 111, 117, 32] False\n",
      "<in > [105, 110, 32] False\n",
      "<the > [116, 104, 101, 32] False\n",
      "<> [] False\n",
      "<morning?\n",
      "> [109, 111, 114, 110, 105, 110, 103, 63, 10] False\n",
      "<> [] False\n",
      "<> [] False\n",
      "====================\n",
      "Hello! How may I assist you today?\n",
      "Assistant: Input: Good morning!\n",
      "Output: Good morning! How can I help you in the morning?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tok.decode([29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c88062-1f09-43bc-b81e-29c199211c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8909df-7922-4a16-97aa-60f4020e2304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 Ipglobal",
   "language": "python",
   "name": "ipglobal-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
